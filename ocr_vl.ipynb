{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a369a50a",
   "metadata": {},
   "source": [
    "#### base版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e2a14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cheng\\miniconda3\\envs\\paddle_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\cheng\\miniconda3\\envs\\paddle_env\\lib\\site-packages\\paddle\\utils\\cpp_extension\\extension_utils.py:718: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001b[32mCreating model: ('PP-DocLayoutV2', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\cheng\\.paddlex\\official_models\\PP-DocLayoutV2`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PaddleOCR-VL-0.9B', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\cheng\\.paddlex\\official_models\\PaddleOCR-VL`.\u001b[0m\n",
      "\u001b[32mLoading configuration file C:\\Users\\cheng\\.paddlex\\official_models\\PaddleOCR-VL\\PaddleOCR-VL-0.9B\\config.json\u001b[0m\n",
      "\u001b[32mLoading weights file C:\\Users\\cheng\\.paddlex\\official_models\\PaddleOCR-VL\\PaddleOCR-VL-0.9B\\model.safetensors\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
      "c:\\Users\\cheng\\miniconda3\\envs\\paddle_env\\lib\\site-packages\\paddle\\utils\\decorator_utils.py:420: Warning: \n",
      "Non compatible API. Please refer to https://www.paddlepaddle.org.cn/documentation/docs/en/develop/guides/model_convert/convert_from_pytorch/api_difference/torch/torch.split.html first.\n",
      "  warnings.warn(\n",
      "\u001b[32mLoaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32mAll model checkpoint weights were used when initializing PaddleOCRVLForConditionalGeneration.\n",
      "\u001b[0m\n",
      "\u001b[32mAll the weights of PaddleOCRVLForConditionalGeneration were initialized from the model checkpoint at C:\\Users\\cheng\\.paddlex\\official_models\\PaddleOCR-VL\\PaddleOCR-VL-0.9B.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use PaddleOCRVLForConditionalGeneration for predictions without further training.\u001b[0m\n",
      "\u001b[32mLoading configuration file C:\\Users\\cheng\\.paddlex\\official_models\\PaddleOCR-VL\\PaddleOCR-VL-0.9B\\generation_config.json\u001b[0m\n",
      "\u001b[33mCurrently, the PaddleOCR-VL-0.9B local model only supports batch size of 1. The batch size will be updated to 1.\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception from the 'cv' worker: Image read Error: E:\\OneDrive\\商汤\\商汤FVTPL2506\\4_资料清单\\客户答复\\09_卢卡杭州\\卢卡 to 商汤\\杭州卢卡报表0331\\杭州卢卡报表0331_01.jpg",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpaddleocr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PaddleOCRVL  \u001b[38;5;66;03m# pyright: ignore[reportMissingImports]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m PaddleOCRVL()\n\u001b[1;32m----> 5\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mOneDrive\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m商汤\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m商汤FVTPL2506\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m4_资料清单\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m客户答复\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m09_卢卡杭州\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m卢卡 to 商汤\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m杭州卢卡报表0331\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m杭州卢卡报表0331_01.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m output:\n\u001b[0;32m      7\u001b[0m     res\u001b[38;5;241m.\u001b[39mprint() \u001b[38;5;66;03m## 打印预测的结构化输出\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cheng\\miniconda3\\envs\\paddle_env\\lib\\site-packages\\paddleocr\\_pipelines\\paddleocr_vl.py:134\u001b[0m, in \u001b[0;36mPaddleOCRVL.predict\u001b[1;34m(self, input, use_doc_orientation_classify, use_doc_unwarping, use_layout_detection, use_chart_recognition, layout_threshold, layout_nms, layout_unclip_ratio, layout_merge_bboxes_mode, use_queues, prompt_label, format_block_content, repetition_penalty, temperature, top_p, min_pixels, max_pixels, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    133\u001b[0m ):\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_doc_orientation_classify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_doc_orientation_classify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_doc_unwarping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_doc_unwarping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_layout_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_layout_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_chart_recognition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_chart_recognition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayout_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayout_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayout_nms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayout_nms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayout_unclip_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayout_unclip_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayout_merge_bboxes_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayout_merge_bboxes_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_queues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_queues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprompt_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m            \u001b[49m\u001b[43mformat_block_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_block_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_pixels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_pixels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_pixels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_pixels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cheng\\miniconda3\\envs\\paddle_env\\lib\\site-packages\\paddlex\\inference\\pipelines\\_parallel.py:129\u001b[0m, in \u001b[0;36mAutoParallelSimpleInferencePipeline.predict\u001b[1;34m(self, input, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    127\u001b[0m     )\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    133\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\cheng\\miniconda3\\envs\\paddle_env\\lib\\site-packages\\paddlex\\inference\\pipelines\\paddleocr_vl\\pipeline.py:656\u001b[0m, in \u001b[0;36m_PaddleOCRVLPipeline.predict\u001b[1;34m(self, input, use_doc_orientation_classify, use_doc_unwarping, use_layout_detection, use_chart_recognition, layout_threshold, layout_nms, layout_unclip_ratio, layout_merge_bboxes_mode, use_queues, prompt_label, format_block_content, repetition_penalty, temperature, top_p, min_pixels, max_pixels, **kwargs)\u001b[0m\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m item[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 656\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    657\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException from the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m worker: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    658\u001b[0m     )\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m item[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Exception from the 'cv' worker: Image read Error: E:\\OneDrive\\商汤\\商汤FVTPL2506\\4_资料清单\\客户答复\\09_卢卡杭州\\卢卡 to 商汤\\杭州卢卡报表0331\\杭州卢卡报表0331_01.jpg"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCRVL  # pyright: ignore[reportMissingImports]\n",
    "\n",
    "pipeline = PaddleOCRVL()\n",
    "\n",
    "output = pipeline.predict(r\"e:\\OneDrive\\project_code\\output\\vision_temp\\pdf_images_25840_642\\page_098.png\")\n",
    "for res in output:\n",
    "    res.print() ## 打印预测的结构化输出\n",
    "    res.save_to_json(save_path=\"output\") ## 保存当前图像的结构化json结果\n",
    "    res.save_to_markdown(save_path=\"output\") ## 保存当前图像的markdown格式的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d0d86",
   "metadata": {},
   "source": [
    "#### 用8000端口api形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "751e5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMkit.modules.vision.ocr_client import OCRClient  # pyright: ignore[reportMissingImports]\n",
    "from pathlib import Path\n",
    "from LLMkit import output_address  # pyright: ignore[reportMissingImports]\n",
    "client = OCRClient(\"http://100.107.137.48:8000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832a4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'error', 'message': 'Failed to recognize image: 400 Client Error: Bad Request for url: http://100.107.137.48:8000/ocr/recognize'}\n"
     ]
    }
   ],
   "source": [
    "# 使用你的文件路径\n",
    "result = client.recognize_image(\n",
    "    image_path=r\"e:\\OneDrive\\project_code\\output\\vision_temp\\pdf_images_25840_642\\page_098.png\",\n",
    "    save_markdown=True,\n",
    "    save_json=False,\n",
    "    output_dir=\"output\"\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11443ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_path = result.get(\"markdown_path\")\n",
    "if md_path:\n",
    "    md_path_full = Path(output_address+md_path[7:])\n",
    "\n",
    "import os\n",
    "os.startfile(md_path_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dc83aa",
   "metadata": {},
   "source": [
    "#### 批量整合md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623ee5ed",
   "metadata": {},
   "source": [
    "pdf转图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa94cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:LLMkit.modules.vision.document_processor:开始处理文档: E:\\OneDrive\\project_code\\杭州卢卡报表0331.pdf\n",
      "INFO:LLMkit.modules.vision.document_processor:已处理第 1 页: e:\\OneDrive\\project_code\\output\\vision_temp\\pdf_images_44284_6959\\page_001.png\n",
      "INFO:LLMkit.modules.vision.document_processor:已处理第 2 页: e:\\OneDrive\\project_code\\output\\vision_temp\\pdf_images_44284_6959\\page_002.png\n",
      "INFO:LLMkit.modules.vision.document_processor:已处理第 3 页: e:\\OneDrive\\project_code\\output\\vision_temp\\pdf_images_44284_6959\\page_003.png\n"
     ]
    }
   ],
   "source": [
    "from LLMkit.modules.vision.document_processor import DocumentProcessor\n",
    "\n",
    "app = DocumentProcessor(dpi = 200)\n",
    "png_result = app.process_document(r\"E:\\OneDrive\\project_code\\杭州卢卡报表0331.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362aa538",
   "metadata": {},
   "source": [
    "图片处理合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "771c4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e:\\\\OneDrive\\\\project_code\\\\output\\\\vision_temp\\\\pdf_images_44284_6959\\\\page_001.png', 'e:\\\\OneDrive\\\\project_code\\\\output\\\\vision_temp\\\\pdf_images_44284_6959\\\\page_002.png', 'e:\\\\OneDrive\\\\project_code\\\\output\\\\vision_temp\\\\pdf_images_44284_6959\\\\page_003.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dir_path = r\"e:\\OneDrive\\project_code\\output\\vision_temp\\pdf_images_25840_642\"\n",
    "\n",
    "dir_path = png_result[0][\"output_dir\"]\n",
    "file_list = [os.path.join(dir_path, f) for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))]\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a30b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "\n",
    "for x in file_list[0:1]:\n",
    "    # 使用你的文件路径\n",
    "    result = client.recognize_image(\n",
    "        image_path=x,\n",
    "        save_markdown=True,\n",
    "        save_json=False,\n",
    "        output_dir=\"output\"\n",
    "    )\n",
    "\n",
    "    md_path = result.get(\"markdown_path\")\n",
    "    if md_path:\n",
    "        md_content = Path(output_address+md_path[7:]).read_text(encoding=\"utf-8\")\n",
    "    content.append(md_content)\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e489a9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存合并后的markdown到: merged_output.md\n"
     ]
    }
   ],
   "source": [
    "md_output_path = \"merged_output.md\"\n",
    "\n",
    "with open(md_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for md in content:\n",
    "        if md:\n",
    "            f.write(md)\n",
    "            f.write(\"\\n\\n\")  # 可选：让每个md之间有空行，便于分隔\n",
    "\n",
    "print(f\"已保存合并后的markdown到: {md_output_path}\")\n",
    "\n",
    "import os\n",
    "\n",
    "if md_path:\n",
    "    os.startfile(md_output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
